# SPMN
Stimulus-Perception Memory Networks：Optimizing Cognitive Agents' Brain-like Memory.

------



## 前言

智能体（指类人智能，具有和人一样的思考、决策、行动等能力）的研究以及开发与人类本身息息相关，我们总能够从人类的身上获取实现智能体技术可能性。智能体的大脑可以类似于人类大脑，通过不同的功能分区来实现不同功能，例如：对语言的理解能力、对所见（视觉感知）的理解能力、情感表达能力、记忆能力等等，而不同功能就如同一个个计算机主板上的零部件，就像输入设备、输出设备、存储器、处理器等，他们通过总线系统进行数据的传输来实现信息交互。智能体也是如此，不同的功能分区是并行的，他们的输入输出可以受晶振产生的时钟进行触发。

而这所有的功能分区模块中最重要的就是记忆模块，如何去理解外界即如何去感知、如何去表达、如何去行动与决策对于智能体来说不是一成不变的，就像人一样他会随着记忆的不断变化而发生改变。例如：三年前的我和现在的我同时走过一条河的时候，对其的感受是不同的，三年后的自己可能仅仅会因为一条河流的风景而变得更感性和产生更多的联想，这是因为不同时间之下记忆产生的差距。

记忆的发生是实时的，是不可控的，是绝对虚假的。人们通常会在独处的时候、高强度精力集中的工作之后、深夜的时候发生类似于胡思乱想、走神等情况，而这种情况往往是不可控的，即我们无法控制我们不发生胡思乱想或者走神的行为，但是我们可以很快的将我们自己从这种状态里面拉出来，此时所想的事情也往往的和自己密切相关或者是印象深刻或者是具有极度的欲望或者想法的，这是大脑表层生物电刺激较为强烈的部分（记忆部分），也正因为这部分刺激的强烈，这也会使得我们去思考和回忆，往往是最近令自己有极大情绪波动的事情，这也正是抑郁症患者经常会陷入不好的回忆和痛苦的过往之中的原因。我们经常会遇到一个情况，即我记得我曾经去买了一本书在某时某地，但是和我随行的人却记得我是去买的另外一本书在某时某地（和我自己的记忆发生了出入且随行的人的记忆是正确的），这是因为触发了大脑的自我保护机制，大脑在记忆事情的时候，往往无法刻意记住事情的全貌，而是去记住自己认为更为重要的事情（对自己刺激较大的事情），就比如这里的去买书这件事以及某时某地，但是具体买了什么书可能并不重要对于自己来说，大脑选择性的进行了遗忘，但是当你去回忆的时候为了防止陷入记忆缺失的矛盾和痛苦，大脑触发了自我保护机制，即根据你现有的记忆（可能是深层记忆，也可能是浅层记忆）你喜欢读书A，所以大脑就把书A记作你去买的书，从而你记住了一个错误的、虚假的“事实”。

仿照人类大脑记忆的功能，并结合现有的记忆网络、脉冲神经网络等的类脑智能研究成果以及深度学习模型优势，本文提出了一种更接近人类真实记忆系统且具有良好的数学解释性的深度学习算法模型——SPMN。

基础架构从全连接算子到卷积算子。卷积层通过共享权重（filter/kernels）来提取局部特征。每个卷积核的参数数量是固定的，与输入的大小无关的特性决定了在大量数据特征下具有比全连接更高效、更迅速的计算效率。刺激记忆比如桌子、椅子、书、树、红、黄、蓝等元素批次之前存在逐渐减弱的相关关系，大量的刺激属性之间只有局部感受野内才具备联系关系，这和卷积计算有异曲同工之妙。

## Preface

The study and development of agents—defined here as human-like intelligences capable of thought, decision-making, and action—are inextricably linked to humanity itself. The possibilities for realizing agent technologies are continually informed by human cognition and behavior. The agent's "brain" can be analogized to the human brain, with distinct functional regions performing specialized tasks such as language comprehension, visual perception, emotional expression, and memory. These functional regions operate similarly to components on a computer motherboard—input devices, output devices, memory, and processors—all interconnected via a bus system for data transmission and information exchange. Likewise, in agents, these functional regions function in parallel, with their input and output processes synchronized by clock signals generated by an oscillator.

Among all these functional modules, the memory module is paramount. For agents, perception, expression, and decision-making are not static; they evolve dynamically, much like human cognition, which changes as memories accumulate and transform over time. For instance, when comparing my experience of walking across a river three years ago to the present, my perception of the river would differ significantly. The version of myself three years from now might feel more sentimental or make richer associations due to the river’s scenery, illustrating how memory gaps across time influence perception.

Memory formation is inherently real-time, uncontrollable, and subjectively constructed. People often experience involuntary mental wandering, especially during moments of solitude, after periods of intense concentration, or late at night. These episodes are typically uncontrollable, yet we can usually extricate ourselves from such states relatively quickly. The thoughts that emerge during these moments are often personally significant, deeply ingrained, or tied to intense desires or preoccupations. These are regions of the brain where superficial bioelectrical stimulation (related to memory) is particularly strong. The intensity of this stimulation drives our reflections and recollections, often focusing on recent events that elicited strong emotional responses. This phenomenon explains why individuals with depression frequently become trapped in negative memories and painful past experiences.

A common scenario illustrates this further: I might recall purchasing a specific book at a certain time and place, while someone accompanying me remembers that I bought a different book under the same circumstances. This discrepancy arises from the brain’s self-protection mechanisms. When forming memories, the brain does not deliberately retain the complete details of an event but prioritizes aspects it deems most significant (those with the strongest emotional or cognitive impact). For example, in the case of buying a book, the time and location might be remembered, but the specific title might be deemed less important and thus selectively forgotten. To avoid the cognitive dissonance and distress of memory gaps, the brain activates its self-protection mechanism. Drawing on existing memories—whether superficial or deeply ingrained—it might reconstruct the memory by associating my preference for a particular book (Book A) and falsely attribute that book to the purchase. This results in the retention of an incorrect yet subjectively coherent "fact."

Drawing inspiration from the memory functions of the human brain and integrating insights from brain-inspired intelligence research, such as memory networks and spiking neural networks, as well as the advantages of deep learning models, this paper proposes a novel deep learning algorithm model—SPMN. This model aims to more closely approximate the human memory system while maintaining robust mathematical interpretability.

------



## 算法概要

### 模型算法 

#### V-0.0.1

描述：最初版本，由纯神经网络组成（卷积网络+全连接网络），类似于LSTM网络结构。

![image-20250408171234128](img\image-20250408171234128.png)

#### V-0.0.2

描述：SPMN 脉冲神经网络版本，由第二代神经网络到第三代神经网络进行过渡，重新设计门结构。通过Encoder处理多模态输入，通过Decoder通过Recall结构解析记忆提取内容得到时间线索、内容线索。三者可并行进行。

模型整体架构：

![image-20250410161915110](img\image-20250410160039564.png)



### 模型训练

#### 0. 预检验记忆能力

![image-20250408184443293](img\image-20250408184443293.png)

其中ABC代表输入事件特征。首先对记忆体M进行复制，得到多个相同参数的记忆体，同时对事件ABC进行记忆，模拟控制单一变量的效果。对记忆体的变化量进行相似度计算和损失计算，使其可以区分不同事件之间的语义区别与联系。

##### 相似度计算：

MAELoss(SimilarF（A， B）, SimilarF（dAM， dBM）)

MAELoss(SimilarF（B， C）, SimilarF（dBM， dCM）)

MAELoss(SimilarF（A， C）, SimilarF（dAM， dCM）)

通过大量的数据特征类型来训练，使其可以对不同数据特征类型进行语义空间级别的区分（记忆）

##### 关键代码实现：

```python
# 计算相似度
similarities1 = torch.matmul(input_flat, input_flat.T)
similarities2 = torch.matmul(sentence_embedding_flat, sentence_embedding_flat.T)

# 计算相似度比值
similarity_ratios = similarities1 / similarities2

# 计算损失，目标是使得比值接近 1
upper_indices = torch.triu_indices(bs, bs, offset=1)
similarity_ratios = similarity_ratios[upper_indices[0], upper_indices[1]]

loss = torch.mean((similarity_ratios - 1) ** 2 / 2)
```

##### 数据集：

dataset\corpus_clean.txt

```python
# top10
我还有几天过生日
达德尼昂兀自立在他俩面前，他俩也面对他停住了脚步。
不就是这么回事吗？
女子撑竿跳高距离田径场不到75英里。
杨幂胡歌到底是什么关系啊
凡尼亚躺在席子底下一动不动。
一群人走在一座雾蒙蒙的山脚下。
花呗于期还款会怎样
回家过年拼车
当他们走近战士的院子时，乔恩在三条街的广场上拦住了他们。
```

#### 1. 预检验时空记忆能力

#### 2. BABI任务训练



------



## 参考文献

##### EntNet

[[1612.03969\] Tracking the World State with Recurrent Entity Networks](https://arxiv.org/abs/1612.03969)

##### Memory Networks

[[1410.3916\] Memory Networks](https://arxiv.org/abs/1410.3916)
