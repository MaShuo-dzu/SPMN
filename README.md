# SPMN
Stimulus-Perception Memory Networks：Optimizing Cognitive Agents' Brain-like Memory.

------



## 前言

智能体（指类人智能，具有和人一样的思考、决策、行动等能力）的研究以及开发与人类本身息息相关，我们总能够从人类的身上获取实现智能体技术可能性。智能体的大脑可以类似于人类大脑，通过不同的功能分区来实现不同功能，例如：对语言的理解能力、对所见（视觉感知）的理解能力、情感表达能力、记忆能力等等，而不同功能就如同一个个计算机主板上的零部件，就像输入设备、输出设备、存储器、处理器等，他们通过总线系统进行数据的传输来实现信息交互。智能体也是如此，不同的功能分区是并行的，他们的输入输出可以受晶振产生的时钟进行触发。

而这所有的功能分区模块中最重要的就是记忆模块，如何去理解外界即如何去感知、如何去表达、如何去行动与决策对于智能体来说不是一成不变的，就像人一样他会随着记忆的不断变化而发生改变。例如：三年前的我和现在的我同时走过一条河的时候，对其的感受是不同的，三年后的自己可能仅仅会因为一条河流的风景而变得更感性和产生更多的联想，这是因为不同时间之下记忆产生的差距。

记忆的发生是实时的，是不可控的，是绝对虚假的。人们通常会在独处的时候、高强度精力集中的工作之后、深夜的时候发生类似于胡思乱想、走神等情况，而这种情况往往是不可控的，即我们无法控制我们不发生胡思乱想或者走神的行为，但是我们可以很快的将我们自己从这种状态里面拉出来，此时所想的事情也往往的和自己密切相关或者是印象深刻或者是具有极度的欲望或者想法的，这是大脑表层生物电刺激较为强烈的部分（记忆部分），也正因为这部分刺激的强烈，这也会使得我们去思考和回忆，往往是最近令自己有极大情绪波动的事情，这也正是抑郁症患者经常会陷入不好的回忆和痛苦的过往之中的原因。我们经常会遇到一个情况，即我记得我曾经去买了一本书在某时某地，但是和我随行的人却记得我是去买的另外一本书在某时某地（和我自己的记忆发生了出入且随行的人的记忆是正确的），这是因为触发了大脑的自我保护机制，大脑在记忆事情的时候，往往无法刻意记住事情的全貌，而是去记住自己认为更为重要的事情（对自己刺激较大的事情），就比如这里的去买书这件事以及某时某地，但是具体买了什么书可能并不重要对于自己来说，大脑选择性的进行了遗忘，但是当你去回忆的时候为了防止陷入记忆缺失的矛盾和痛苦，大脑触发了自我保护机制，即根据你现有的记忆（可能是深层记忆，也可能是浅层记忆）你喜欢读书A，所以大脑就把书A记作你去买的书，从而你记住了一个错误的、虚假的“事实”。

仿照人类大脑记忆的功能，并结合现有的记忆网络、脉冲神经网络等的类脑智能研究成果以及深度学习模型优势，本文提出了一种更接近人类真实记忆系统且具有良好的数学解释性的深度学习算法模型——SPMN。

基础架构从全连接算子到卷积算子。卷积层通过共享权重（filter/kernels）来提取局部特征。每个卷积核的参数数量是固定的，与输入的大小无关的特性决定了在大量数据特征下具有比全连接更高效、更迅速的计算效率。刺激记忆比如桌子、椅子、书、树、红、黄、蓝等元素批次之前存在逐渐减弱的相关关系，大量的刺激属性之间只有局部感受野内才具备联系关系，这和卷积计算有异曲同工之妙。

## Preface

The study and development of agents—defined here as human-like intelligences capable of thought, decision-making, and action—are inextricably linked to humanity itself. The possibilities for realizing agent technologies are continually informed by human cognition and behavior. The agent's "brain" can be analogized to the human brain, with distinct functional regions performing specialized tasks such as language comprehension, visual perception, emotional expression, and memory. These functional regions operate similarly to components on a computer motherboard—input devices, output devices, memory, and processors—all interconnected via a bus system for data transmission and information exchange. Likewise, in agents, these functional regions function in parallel, with their input and output processes synchronized by clock signals generated by an oscillator.

Among all these functional modules, the memory module is paramount. For agents, perception, expression, and decision-making are not static; they evolve dynamically, much like human cognition, which changes as memories accumulate and transform over time. For instance, when comparing my experience of walking across a river three years ago to the present, my perception of the river would differ significantly. The version of myself three years from now might feel more sentimental or make richer associations due to the river’s scenery, illustrating how memory gaps across time influence perception.

Memory formation is inherently real-time, uncontrollable, and subjectively constructed. People often experience involuntary mental wandering, especially during moments of solitude, after periods of intense concentration, or late at night. These episodes are typically uncontrollable, yet we can usually extricate ourselves from such states relatively quickly. The thoughts that emerge during these moments are often personally significant, deeply ingrained, or tied to intense desires or preoccupations. These are regions of the brain where superficial bioelectrical stimulation (related to memory) is particularly strong. The intensity of this stimulation drives our reflections and recollections, often focusing on recent events that elicited strong emotional responses. This phenomenon explains why individuals with depression frequently become trapped in negative memories and painful past experiences.

A common scenario illustrates this further: I might recall purchasing a specific book at a certain time and place, while someone accompanying me remembers that I bought a different book under the same circumstances. This discrepancy arises from the brain’s self-protection mechanisms. When forming memories, the brain does not deliberately retain the complete details of an event but prioritizes aspects it deems most significant (those with the strongest emotional or cognitive impact). For example, in the case of buying a book, the time and location might be remembered, but the specific title might be deemed less important and thus selectively forgotten. To avoid the cognitive dissonance and distress of memory gaps, the brain activates its self-protection mechanism. Drawing on existing memories—whether superficial or deeply ingrained—it might reconstruct the memory by associating my preference for a particular book (Book A) and falsely attribute that book to the purchase. This results in the retention of an incorrect yet subjectively coherent "fact."

Drawing inspiration from the memory functions of the human brain and integrating insights from brain-inspired intelligence research, such as memory networks and spiking neural networks, as well as the advantages of deep learning models, this paper proposes a novel deep learning algorithm model—SPMN. This model aims to more closely approximate the human memory system while maintaining robust mathematical interpretability.

------



## 算法概要

### 模型算法 

#### V-0.0.1

描述：最初版本，由纯神经网络组成（卷积网络+全连接网络），类似于LSTM网络结构。

![image-20250408171234128](.\img\image-20250408171234128.png)

#### V-0.0.2

描述：SPMN 脉冲神经网络版本，由第二代神经网络到第三代神经网络进行过渡，重新设计门结构。通过Encoder处理多模态输入，通过Decoder通过Recall结构解析记忆提取内容得到时间线索、内容线索。三者可并行进行。

模型整体架构：

![image-20250410161915110](.\img\image-20250410160039564.png)



### 模型训练

#### 0. 预检验相互关系识别能力

![image-20250408184443293](img\image-20250408184443293.png)

其中ABC代表输入事件特征。首先对记忆体M进行复制，得到多个相同参数的记忆体，同时对事件ABC进行记忆，模拟控制单一变量的效果。对记忆体的变化量进行相似度计算和损失计算，使其可以区分不同事件之间的语义区别与联系。

##### 相似度计算：

MAELoss(SimilarF（A， B）, SimilarF（dAM， dBM）)

MAELoss(SimilarF（B， C）, SimilarF（dBM， dCM）)

MAELoss(SimilarF（A， C）, SimilarF（dAM， dCM）)

通过大量的数据特征类型来训练，使其可以对不同数据特征类型进行语义空间级别的区分（记忆）

**含有先验知识的相似度计算**

传统的相似度计算比如余弦相似度、距离计算、相关性系数计算等等存在明显缺陷。他们无法处理语义上的关系，对于向量类型的计算例如点积计算、余弦相似度计算通过将词序的方向当作语义。除此之外，还有很多种情况这些相似度计算难以去考虑全面，例如：倒装语句情况（对于倒装语句类型，在向量的方向是完全相反的：“中午我吃了xx”与“我中午吃了xx”与“我中午在xx吃的”，这会产生巨大的差异性尽管他们只是次序上的差异）；词语义替换的情况（例如：“我在读鲁迅的著作”与“我在读周树人的著作”，如果不含有鲁迅和周树人的先验知识，这两句就会获得较大的差异关系）；词语义包含的情况（例如：“我今天中午面食吃的面条”与“我今天12点左右面食吃的面条”）等等情况，尤其是当这些情况同时发生或者相互作用的时候，往往会不断放大这种差异性。

对于人类的记忆来说，记住了什么以及怎么去记住同时取决于自己先验知识，即曾经的记忆。在进行记忆能力预检验事件相似度计算的时候，事件的相似度计算还要关系与已有的记忆体M的属性。故放弃传统的相似度而使用带有先验知识的相似度计算则显得尤其重要。

**建立分词先验关系**

为避免引入难以解释的超参数影响，我们避免使用深度学习、机器学习技术等，比如聚类计算、Z-score、IQR等方法。先验关系图是由分词作为结点，关系程度作为边组成的有向图。先验关系图基于给出的特定先验知识进行构建，例如：鲁迅和周树人是同一个人、12点左右的时间段在“中午”名称的定义之内。

![image-20250413104043993](img\image-20250413104043993.png)

(图例只绘制了部分关系以作参考)

分词两两之间存在的相互关系如下图所示：

1. 相交关系

![image-20250413200938228](img\image-20250413200938228.png)

2. 包含关系

   ![image-20250413201041391](img\image-20250413201041391.png)

3. 无关系

   ![image-20250413201145517](img\image-20250413201145517.png)

4. 重合关系

   ![image-20250413201304885](img\image-20250413201304885.png)

分词之间存在的相互关系无法直接作用在句子之间去对比相似度，例如：句子A（我今天中午在食堂吃的饭）、句子B（我今天中午吃的石锅），食堂->石锅【0.56】，石锅->食堂【0.23】。因此我们需要计算出分词之间的无向关系，如上图所示，分词之间存在相交、互斥等关系，可以通过集合关系来代替分词之间的无向关系。而集合交并比能够很好的反应这两者之间的共同关系。当两个分词处于不相交的位置上，反应分词彼此之间无法相互“推导”，相交的程度越大，象征着分词之间越容易进行相互“推导”。

![image-20250413202801525](img\image-20250413202801525.png)

分词之间关系求解办法：

需要准备一个先验知识句子库（由多个句子组成的数据库，并由其推导出不同分词之间的先验关系），步骤如下：

1. 分词

2. 找出所有的 Xseq -> X 的关系，其中X为分词，Xseq为包含该分词X的不连续字符串序列。例如：先验知识为“你吃了什么？”，X为“你”，所有的Xseq  -> X 关系共有个16。

   ![image-20250414084612284](img\image-20250414084612284.png)

3. 根据Xseq -> X，计算Other -> X的关系：

   ![image-20250414085456282](img\image-20250414085456282.png)

​	其中Count函数用于计算Other在Xseq中的出现次数，Num函数用于计算Xseq在全部先验知识库中的出现次数，All是找出的所有序列数量。

4. 计算Other -> X 的占比：（其中m代表所有分词的总量，Wordx代表Other）

   ![image-20250414090357632](img\image-20250414090357632.png)

计算得到先验关系无向图。

![image-20250414091303693](img\image-20250414091303693.png)

**句子相似度关系表**

通过建立完成分词先验关系，对待计算相似度的句子建立相似度关系表：（根据上面计算X与X之间的关系不一定是1，这里的数值是随机生成的，以作参考）

![image-20250414091701269](img\image-20250414091701269.png)

**求解相似度无向图**

在得到相似度关系表后，需要建立相似度无向图，建立方法：表中非0元素作为图的结点，两个非0元素之间的最短距离作为图的边权。

![17ef0cb50a874c01b619c6eed7cfb04](img\17ef0cb50a874c01b619c6eed7cfb04.png)

通过以下公式求解最后的相似度：

![1376d1f7b2fbbfe1bc4e90c99e0d7a5](img\1376d1f7b2fbbfe1bc4e90c99e0d7a5.png)![648d1dcbac2a78d0a8802cf5c19cc36](img\648d1dcbac2a78d0a8802cf5c19cc36.png)![e88322aff964496eed9b48cfa53ffc9](img\e88322aff964496eed9b48cfa53ffc9.png)

##### 数据集：

dataset\corpus_clean.txt

```python
# top10
我还有几天过生日
达德尼昂兀自立在他俩面前，他俩也面对他停住了脚步。
不就是这么回事吗？
女子撑竿跳高距离田径场不到75英里。
杨幂胡歌到底是什么关系啊
凡尼亚躺在席子底下一动不动。
一群人走在一座雾蒙蒙的山脚下。
花呗于期还款会怎样
回家过年拼车
当他们走近战士的院子时，乔恩在三条街的广场上拦住了他们。
```

#### 1. 预检验时空记忆能力

SPMN网络的输出结果分为两部分，分别为在时间上的预测关系以及在空间上的预测关系。相较于其他记忆网络，他们不仅仅关注于模型的记忆的存留与遗忘，同时加入了模型对记忆理解能力的考量，但是这在人类大脑当中是相违背的，大脑的记忆表现为对外界的刺激的感知，类似于多巴胺或者内啡肽的作用效果，但是对记忆的理解取决于人类后天锻炼的“理解能力”，这相当于现在模型的“参数”，只不过这个参数是一直“训练的”。

手稿草图：

![51b10e09baa40c57bb0749f589762437](img\51b10e09baa40c57bb0749f589762437.png)

#### 2. BABI任务训练

![c20f24df14c8a443b102257acb8f9265](img\c20f24df14c8a443b102257acb8f9265.png)



------



## 参考文献

##### EntNet

[[1612.03969\] Tracking the World State with Recurrent Entity Networks](https://arxiv.org/abs/1612.03969)

##### Memory Networks

[[1410.3916\] Memory Networks](https://arxiv.org/abs/1410.3916)



## 备忘录

梯度健康度检测，损失曲面分析，通过扰动参数绘制损失变化曲线了解损失函数地形；激活值分布监测，查看隐藏层输出方差和神经元激活状态来保障信息传递；模型容量验证，在小批量数据上训练观察损失变化判断模型表达能力 。

在神经元模型方面，ANN通常采用大量简单的计算单元，如修正线性单元（ReLU）、sigmoid函数、tanh函数等，将这些单元相互连接形成复杂神经网络；SNN则采用具有记忆的非差分神经元模型构造神经网络，如霍奇金 ‒ 赫胥黎（H-H）模型、泄漏积分发射（LIF）模型等，具备可提取数据时空特征、功耗更低、更适合并行计算的优势，

韦克斯勒记忆量表数据集

![6a5c4251634ca7e242d16d1eadf89cd2](img\6a5c4251634ca7e242d16d1eadf89cd2.png)
